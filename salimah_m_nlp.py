# -*- coding: utf-8 -*-
"""Salimah M_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1coZuI5ygmHnFnmjxtxUEnhBixrFiY9n7

**Membuat Model NLP**
*   Nama : Salimah Mahdiyyah
*   Email : salimahdiyyah03@gmail.com
*   Link Dataset : https://www.kaggle.com/datasets/niraliivaghani/flipkart-product-customer-reviews-dataset
*   Sumber : Kaggle
"""

from google.colab import drive
drive.mount('/content/drive/')

import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/Dataset-SA.csv')
df = df.drop(columns=['product_name', 'product_price', 'Rate', 'Review'])
df

sen = pd.get_dummies(df.Sentiment)
df = pd.concat([df, sen], axis=1)
df = df.drop(columns='Sentiment')

df

review = df['Summary'].values
label = df[['negative', 'neutral', 'positive']].values

review

label

from sklearn.model_selection import train_test_split

sum = df['Summary'].values
y = df[['negative', 'neutral', 'positive']].values
sum_train, sum_test, y_train, y_test = train_test_split(sum, y, test_size=0.2)

import numpy as np

# Handling NaN values and converting to string for NumPy arrays
sum_train = np.nan_to_num(sum_train, nan='')
sum_test = np.nan_to_num(sum_test, nan='')

sum_train = sum_train.astype(str)
sum_test = sum_test.astype(str)

from tensorflow.keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer(num_words=10000, oov_token='-')
tokenizer.fit_on_texts(sum_train)
tokenizer.fit_on_texts(sum_test)

sekuens_train = tokenizer.texts_to_sequences(sum_train)
sekuens_test = tokenizer.texts_to_sequences(sum_test)

padded_train = pad_sequences(sekuens_train, maxlen=20)
padded_test = pad_sequences(sekuens_test, maxlen=20)

from tensorflow.keras import layers
from tensorflow.keras import Sequential
import tensorflow as tf

model=tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=10000, output_dim=16, input_length=20),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(3, activation='sigmoid')
])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.95):
      print("\nAkurasi di atas 95%, Training Berhenti!")
      self.model.stop_training = True

callbacks = myCallback()

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

print(padded_train.shape)
print(padded_test.shape)

history = model.fit(
    padded_train,
    y_train,
    epochs=30,
    validation_data=(padded_test, y_test),
    batch_size=128,
    verbose=2
)

import matplotlib.pyplot as plt
import seaborn as sns

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc = 'lower right')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc = 'upper left')
plt.show()